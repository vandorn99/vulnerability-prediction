import os
import json
import csv
import argparse
import pandas as pd

from sklearn import linear_model

parser = argparse.ArgumentParser()
parser.add_argument('-m', '--model', metavar='', help='Which model\'s results should be parsed')
parser.add_argument('-a', '--aggregate', action='store_true', help='Whether to create aggregated data or not')
parser.add_argument('-r', '--regression', action='store_true', help='Create linear regression model')
parser.add_argument('-p', '--process_patches', action='store_true', help='Process patches')
args = parser.parse_args()

model_stats = dict()

def process_model(model, rules=None, no_zero=True):
    model_stats[model] = dict()
    for root, dirs, files in os.walk('./' + model + '_results'):
        for file in files:
            stats = dict()
            path = os.path.join(root, file)
            parts = path.split(os.sep)

            file_name = str(parts[-3])
            percentage = str(parts[-2])
            rule = str(parts[-1]).split('.')[0]

            if no_zero and percentage == '0%':
                continue

            if rules is not None and rule not in rules:
                continue

            with open('./tests/files_with_known_issues/' + file_name, 'r') as f:
                original = f.readlines()

            with open(path, 'r') as f:
                tmp = csv.DictReader(f)
                out = list()
                for row in tmp:
                    out.append(row['Line_content'].strip())

            with open('./patches/' + file_name + '.txt', 'r') as f:
                patch = list()
                for line in f.readlines():
                    if len(line) > 2 and not line.startswith('//'):
                        patch.append(line.strip())


            stats['file_lines'] = len(original)
            stats['flagged_lines'] = len(out)
            stats['vuln_lines'] = len(patch)

            flagged_vuln_lines = 0
            for vuln in patch:
                if vuln in out:
                    flagged_vuln_lines += 1

            stats['flagged_vuln_lines'] = flagged_vuln_lines

            stats['%_flagged'] = stats['flagged_lines'] * 100 / stats['file_lines']
            stats['%_is_vuln'] = stats['flagged_vuln_lines'] * 100 / stats['flagged_lines'] if stats['flagged_lines'] > 0 else 0
            stats['%_vuln_flagged'] = stats['flagged_vuln_lines'] * 100 / stats['vuln_lines'] if stats['vuln_lines'] > 0 else 0

            if model_stats.get(model).get(rule) is None:
                model_stats[model][rule] = dict()

            if model_stats.get(model).get(rule).get(file_name) is None:
                model_stats[model][rule][file_name] = dict()

            if model_stats.get(model).get(rule).get(file_name).get(percentage) is None:
                model_stats[model][rule][file_name][percentage] = stats

            with open('./results/' + file_name + '_' + model + '_' + percentage + '_' + rule + '.json', 'w') as f:
                json.dump(stats, f, indent=4)

def create_table():
    file_name = 'result'

    if args.aggregate:
        file_name += '_aggregated'

    with open(file_name + '.csv', 'w') as f:
        line = ',,'

        for model in model_stats.keys():
            for rule in model_stats[model].keys():
                for file in model_stats[model][rule].keys():

                    if args.aggregate:
                        line += ',percentage'
                    else:
                        line += ',' + file

                    for i in range(len(model_stats[model][rule][file]) - 1):
                        line += ','

                    if args.aggregate:
                        break

                line += '\n'
                f.write(line)
                line = ',,'
                for file in model_stats[model][rule].keys():
                    for percentage in model_stats[model][rule][file].keys():
                        line += ',' + percentage

                    if args.aggregate:
                        break

                line += '\n'
                f.write(line)

                break
            break

        for model in model_stats.keys():
            line_file_lines = model
            line_flagged_lines = ','
            line_vuln_lines = ','
            line_flagged_vuln_lines = ','
            line_p_flagged = ','
            line_p_is_vuln = ','
            line_p_vuln_flagged = ','

            needs_header = True

            percentage_data = dict()

            for rule in model_stats[model].keys():
                for file in model_stats[model][rule].keys():
                    for percentage in model_stats[model][rule][file].keys():
                        if needs_header:
                            line_file_lines += ',' + rule + ',file_lines'
                            line_flagged_lines += ',' + 'flagged_lines'
                            line_vuln_lines += ',' + 'vuln_lines'
                            line_flagged_vuln_lines += ',' + 'flagged_vuln_lines'
                            line_p_flagged += ',' + '%_flagged'
                            line_p_is_vuln += ',' + '%_is_vuln'
                            line_p_vuln_flagged += ',' + '%_vuln_flagged'

                        if args.aggregate:
                            if percentage_data.get(percentage) is None:
                                percentage_data[percentage] = dict()
                                percentage_data[percentage]['file_lines'] = 0
                                percentage_data[percentage]['flagged_lines'] = 0
                                percentage_data[percentage]['vuln_lines'] = 0
                                percentage_data[percentage]['flagged_vuln_lines'] = 0
                                percentage_data[percentage]['num_records'] = 0

                            percentage_data[percentage]['file_lines'] += model_stats[model][rule][file][percentage]['file_lines']
                            percentage_data[percentage]['flagged_lines'] += model_stats[model][rule][file][percentage]['flagged_lines']
                            percentage_data[percentage]['vuln_lines'] += model_stats[model][rule][file][percentage]['vuln_lines']
                            percentage_data[percentage]['flagged_vuln_lines'] += model_stats[model][rule][file][percentage]['flagged_vuln_lines']
                            percentage_data[percentage]['num_records'] += 1

                        else:
                            line_file_lines += ',' + str(model_stats[model][rule][file][percentage]['file_lines'])
                            line_flagged_lines += ',' + str(model_stats[model][rule][file][percentage]['flagged_lines'])
                            line_vuln_lines += ',' + str(model_stats[model][rule][file][percentage]['vuln_lines'])
                            line_flagged_vuln_lines += ',' + str(model_stats[model][rule][file][percentage]['flagged_vuln_lines'])
                            line_p_flagged += ',' + str(model_stats[model][rule][file][percentage]['%_flagged'])
                            line_p_is_vuln += ',' + str(model_stats[model][rule][file][percentage]['%_is_vuln'])
                            line_p_vuln_flagged += ',' + str(model_stats[model][rule][file][percentage]['%_vuln_flagged'])

                        needs_header = False

                needs_header = True

                if args.aggregate:
                    for perc in percentage_data.keys():
                        line_p_flagged += ',' + str(percentage_data[perc]['flagged_lines'] * 100 / percentage_data[perc]['file_lines'])
                        line_p_is_vuln += ',' + str(percentage_data[perc]['flagged_vuln_lines'] * 100 / percentage_data[perc]['flagged_lines'] if percentage_data[perc]['flagged_lines'] > 0 else 0)
                        line_p_vuln_flagged += ',' + str(percentage_data[perc]['flagged_vuln_lines'] * 100 / percentage_data[perc]['vuln_lines'] if percentage_data[perc]['vuln_lines'] > 0 else 0)

                        '''
                        num_records = percentage_data[perc]['num_records']
                        percentage_data[perc]['file_lines'] /= num_records
                        percentage_data[perc]['flagged_lines'] /= num_records
                        percentage_data[perc]['vuln_lines'] /= num_records
                        percentage_data[perc]['flagged_vuln_lines'] /= num_records
                        '''

                        line_file_lines += ',' + str(percentage_data[perc]['file_lines'])
                        line_flagged_lines += ',' + str(percentage_data[perc]['flagged_lines'])
                        line_vuln_lines += ',' + str(percentage_data[perc]['vuln_lines'])
                        line_flagged_vuln_lines += ',' + str(percentage_data[perc]['flagged_vuln_lines'])

                line_file_lines += '\n'
                line_flagged_lines += '\n'
                line_vuln_lines += '\n'
                line_flagged_vuln_lines += '\n'
                line_p_flagged += '\n'
                line_p_is_vuln += '\n'
                line_p_vuln_flagged += '\n'

                f.write(line_file_lines)
                f.write(line_flagged_lines)
                f.write(line_vuln_lines)
                f.write(line_flagged_vuln_lines)
                f.write(line_p_flagged)
                f.write(line_p_is_vuln)
                f.write(line_p_vuln_flagged)

                line_file_lines = ''
                line_flagged_lines = ','
                line_vuln_lines = ','
                line_flagged_vuln_lines = ','
                line_p_flagged = ','
                line_p_is_vuln = ','
                line_p_vuln_flagged = ','

                percentage_data = dict()


def regression(model, acceptances):
    rules = ['rule_complex_and_surrounded.csv', 'rule_complex_before_surr.csv']

    data = dict()

    for rule in rules:
        data[rule] = dict()
        data[rule]['distance'] = list()
        data[rule]['surrounding'] = list()
        data[rule]['complexity'] = list()
        data[rule]['class'] = list()

    if not os.path.isdir(f'./{model}_results'):
        return

    for root, dirs, files in os.walk(f'./{model}_results'):
        for file in files:
            path = str(os.path.join(root, file))
            parts = path.split(os.sep)

            rule = parts[-1]
            percentage = parts[-2]

            if percentage not in acceptances or rule not in rules:
                continue

            patch = list()
            with open(f'./patches/{str(parts[1])}.txt', 'r') as f:
                for line in f.readlines():
                    patch.append(line.strip())

            with open(path, 'r') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    content = row['Line_content'].strip()
                    if content in patch:
                        data[rule]['class'].append(1)
                    else:
                        data[rule]['class'].append(0)

                    data[rule]['distance'].append(row['distance'])
                    data[rule]['surrounding'].append(row['surrounding'])
                    data[rule]['complexity'].append(row['complexity'])

    for rule in rules:
        df = pd.DataFrame(data[rule], columns=['distance', 'surrounding', 'complexity', 'class'])

        vuln_lines = df[df['class'] == 1]
        non_vuln_lines = df[df['class'] == 0]
        random_lines = non_vuln_lines.sample(n=len(vuln_lines))
        print(len(vuln_lines))

        vuln_lines = vuln_lines.append(random_lines)
        vuln_lines = vuln_lines.sample(frac=1)


        X = vuln_lines[['distance', 'surrounding', 'complexity']]
        y = vuln_lines['class']

        lmodel = linear_model.LinearRegression()
        lmodel.fit(X, y)

        out = dict()
        if os.path.exists('coeffs.json'):
            with open('coeffs.json', 'r') as f:
                out = json.load(f)

        with open('coeffs.json', 'w') as f:
            out[f'{model}_{rule}'] = f'{lmodel.intercept_} + {lmodel.coef_[0]}*distance + {lmodel.coef_[1]}*surrounding + {lmodel.coef_[2]}*complexity'
            json.dump(out, f, indent=4)


def process_patches():
    if not os.path.isdir('processed_patches'):
        os.mkdir('processed_patches')

    df = pd.read_csv("../vuln_func_raise.csv")
    df = df.dropna(axis=1, how='all').drop('Unnamed: 47', axis=1).dropna().drop_duplicates(subset=['path', 'Fix_hash'])
    df = df[['full_repo_path', 'path', 'Fix_hash']]

    for index, row in df.iterrows():
        file_name = str(row['path']).split("/")[-1].split('.')[0]
        project = str(row['full_repo_path'])
        if project.startswith('www'):
            project = project.split('/')[2]
        else:
            project = project.split('/')[4]

        data = dict()
        data['project'] = project
        data['lines'] = list()

        for _hash in str(row['Fix_hash']).split('-'):
            for root, dirs, files in os.walk(f'../patches/{_hash}'):
                for file in files:
                    correct = False
                    with open(os.path.join(root, file), 'r') as f:
                        for line in f.readlines():
                            if line.startswith('---'):
                                if line.endswith(file_name + '.js\n'):
                                    correct = True
                                else:
                                    correct = False
                            elif correct and line.startswith('-'):
                                content = "-".join(line.split('-')[1:]).strip()
                                if len(content.split(' ')) > 1:
                                    data['lines'].append(content)

        for i in range(1, len(df)):
            if not os.path.exists(f'processed_patches/{file_name}{"" if i == 1 else i}.json'):
                with open(f'processed_patches/{file_name}{"" if i == 1 else i}.json', 'w') as f:
                    json.dump(data, f, indent=4)
                break


def one_vuln_line():
    counter = 0
    total = 0
    for root, dirs, files in os.walk('processed_patches'):
        for file in files:
            total += 1
            with open(os.path.join(root, file), 'r') as f:
                data = json.load(f)
                if len(data['lines']) == 1:
                    counter += 1
    print(counter / total)


def main():
    if args.process_patches:
        process_patches()
    elif args.model:
        acceptances = ['0%']
        rules = ['rule_complex_and_surrounded_reg', 'rule_complex_before_surr_reg']
        with open(args.model, 'r') as f:
            for line in f.readlines():
                if args.regression:
                    regression(line.strip(), acceptances)
                else:
                    process_model(line.strip(), rules)
                    create_table()
    else:
        one_vuln_line()


main()
