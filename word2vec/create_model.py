import os
import json
import subprocess
import glob
from concurrent.futures import ThreadPoolExecutor
import gensim.models.word2vec as wv

CORES = os.cpu_count() + 4

def task(num, root, file):
    subprocess.run(f'node ./index.js {os.path.join(root, file)} {keywords} {num}')

js_path = './js'

files = glob.glob('./temp_corp/*')
for f in files:
    os.remove(f)

with open('keywords.txt', 'r') as k:
    keywords = ""
    for line in k.readlines():
        keywords += line.rstrip() + ","

with ThreadPoolExecutor(max_workers=CORES) as executor:
    i=0
    for root, dirs, files in os.walk(js_path):
        for file in files:
            executor.submit(task, i%CORES, root, file)
            i += 1

with open('corpus.txt', 'w') as outfile:
    for i in range(0, CORES):
        with open(f'./temp_corp/corpus{i}.txt') as infile:
            for line in infile:
                outfile.write(line)

print("Lexing done!")

sentences = wv.LineSentence('./corpus.txt')

model = wv.Word2Vec(sentences=sentences, min_count=1, workers=CORES)
model.save("word2vec.model")